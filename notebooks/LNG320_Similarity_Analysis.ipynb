{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LNG320 Gen Z Slang Similarity Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU datasets pinecone-client \"langchain==0.3.27\" \"langchain-core>=0.3.72,<1.0.0\" langchain-pinecone umap-learn hdbscan scikit-learn plotly tqdm \"threadpoolctl==3.5.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from typing import Any, Dict, List, Literal, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from IPython.display import display\n",
    "from pinecone import Pinecone\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "\n",
    "import hdbscan\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "try:\n",
    "    import umap  # type: ignore\n",
    "except ImportError:  # pragma: no cover\n",
    "    import umap.umap_ as umap  # fallback if namespace layout differs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"PINECONE_API_KEY\" not in os.environ or not os.environ[\"PINECONE_API_KEY\"]:\n",
    "    os.environ[\"PINECONE_API_KEY\"] = getpass(\"Enter your Pinecone API key: \")\n",
    "\n",
    "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ds = load_dataset(\"MLBtrio/genz-slang-dataset\", split=\"train\")\n",
    "df = raw_ds.to_pandas().copy()\n",
    "\n",
    "df.columns = [col.lower().strip() for col in df.columns]\n",
    "slang_column = \"slang\"\n",
    "\n",
    "df[\"input_for_embedding\"] = (\n",
    "    df[slang_column].astype(str)\n",
    "    + \" is a slang term that means \"\n",
    "    + df[\"description\"].astype(str)\n",
    ")\n",
    "\n",
    "display(df.head())\n",
    "print(f\"Dataset shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "df[\"id\"] = [\n",
    "    str(uuid.uuid5(uuid.NAMESPACE_DNS, term)) for term in df[slang_column].astype(str)\n",
    "]\n",
    "print(\"Sample IDs:\")\n",
    "display(df[[\"slang\", \"id\"]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pinecone Index Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"lng320-genz-slang\"\n",
    "\n",
    "existing_indexes = {item[\"name\"] for item in pc.list_indexes()}\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index_for_model(\n",
    "        name=index_name,\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\",\n",
    "        embed={\n",
    "            \"model\": \"llama-text-embed-v2\",\n",
    "            \"field_map\": {\"text\": \"input_for_embedding\"},\n",
    "        },\n",
    "    )\n",
    "    print(f\"Created index '{index_name}'\")\n",
    "else:\n",
    "    print(f\"Using existing index '{index_name}'\")\n",
    "\n",
    "index = pc.Index(index_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate or Retrieve Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_EMBEDDINGS = False\n",
    "\n",
    "if GENERATE_EMBEDDINGS:\n",
    "    texts = df[\"input_for_embedding\"].tolist()\n",
    "    batch_size = 96\n",
    "    embeddings: List[List[float]] = []\n",
    "\n",
    "    for start in tqdm(range(0, len(texts), batch_size), desc=\"Embedding batches\"):\n",
    "        batch = texts[start : start + batch_size]\n",
    "        embed_result = pc.inference.embed(\n",
    "            model=\"llama-text-embed-v2\",\n",
    "            inputs=batch,\n",
    "            parameters={\"input_type\": \"passage\"},\n",
    "        )\n",
    "        batch_embeddings = [item.values for item in embed_result.data]\n",
    "        embeddings.extend(batch_embeddings)\n",
    "\n",
    "    df[\"values\"] = embeddings\n",
    "    print(f\"Generated {len(df)} embeddings\")\n",
    "else:\n",
    "    fetched_vectors: Dict[str, List[float]] = {}\n",
    "    batch_size = 200\n",
    "    for start in tqdm(range(0, len(df), batch_size), desc=\"Fetching embeddings\"):\n",
    "        batch_ids = df[\"id\"].iloc[start : start + batch_size].tolist()\n",
    "        response = index.fetch(ids=batch_ids)\n",
    "        fetched_vectors.update(\n",
    "            {item[0]: item[1][\"values\"] for item in response.vectors.items()}\n",
    "        )\n",
    "\n",
    "    df[\"values\"] = [fetched_vectors[row.id] for row in df.itertuples(index=False)]\n",
    "    missing = [\n",
    "        row.id for row in df.itertuples(index=False) if row.id not in fetched_vectors\n",
    "    ]\n",
    "    if missing:\n",
    "        raise RuntimeError(\n",
    "            f\"Missing vectors for {len(missing)} ids. Regenerate embeddings instead.\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_EMBEDDINGS:\n",
    "    vectors = [\n",
    "        {\n",
    "            \"id\": row.id,\n",
    "            \"values\": row.values,\n",
    "            \"metadata\": {\"text\": row.input_for_embedding},\n",
    "        }\n",
    "        for row in df.itertuples(index=False)\n",
    "    ]\n",
    "    batch_size = 100\n",
    "    for start in tqdm(range(0, len(vectors), batch_size), desc=\"Upserting to Pinecone\"):\n",
    "        index.upsert(vectors=vectors[start : start + batch_size])\n",
    "    print(\"Upserted embeddings to Pinecone\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.vstack(df[\"values\"].to_numpy())\n",
    "print(f\"Embedding matrix shape: {embedding_matrix.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "umap_model = umap.UMAP(n_components=2, metric=\"cosine\", random_state=42)\n",
    "umap_coords = umap_model.fit_transform(embedding_matrix)\n",
    "\n",
    "viz_df = df[[\"id\", \"slang\", \"description\"]].copy()\n",
    "viz_df[[\"umap_x\", \"umap_y\"]] = umap_coords\n",
    "\n",
    "viz_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HDBSCAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=5,\n",
    "    min_samples=3,\n",
    "    cluster_selection_method=\"eom\",\n",
    "    metric=\"euclidean\",\n",
    ")\n",
    "cluster_labels = clusterer.fit_predict(umap_coords)\n",
    "\n",
    "viz_df[\"cluster\"] = cluster_labels\n",
    "viz_df[\"cluster_prob\"] = clusterer.probabilities_\n",
    "\n",
    "n_clusters = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)\n",
    "n_noise = (cluster_labels == -1).sum()\n",
    "\n",
    "print(f\"Number of clusters: {n_clusters}\")\n",
    "print(f\"Noise points: {n_noise} ({n_noise / len(cluster_labels) * 100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_counts = viz_df[\"cluster\"].value_counts().sort_index()\n",
    "print(\"Cluster distribution:\")\n",
    "display(cluster_counts)\n",
    "\n",
    "print(\"\\nExemplar slang terms per cluster:\")\n",
    "for cluster_id in sorted(viz_df[\"cluster\"].unique()):\n",
    "    cluster_terms = viz_df[viz_df[\"cluster\"] == cluster_id]\n",
    "    top_terms = cluster_terms.nlargest(5, \"cluster_prob\")[\n",
    "        [\"slang\", \"description\", \"cluster_prob\"]\n",
    "    ]\n",
    "    label = \"Noise\" if cluster_id == -1 else f\"Cluster {cluster_id}\"\n",
    "    print(f\"\\n{label} ({len(cluster_terms)} terms):\")\n",
    "    display(top_terms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_df[\"cluster_label\"] = viz_df[\"cluster\"].apply(\n",
    "    lambda x: \"Noise\" if x == -1 else f\"Cluster {x}\"\n",
    ")\n",
    "\n",
    "fig = px.scatter(\n",
    "    viz_df,\n",
    "    x=\"umap_x\",\n",
    "    y=\"umap_y\",\n",
    "    color=\"cluster_label\",\n",
    "    hover_data=[\"slang\", \"description\", \"cluster_prob\"],\n",
    "    title=\"UMAP + HDBSCAN Clustering of Gen Z Slang\",\n",
    "    labels={\"umap_x\": \"UMAP 1\", \"umap_y\": \"UMAP 2\", \"cluster_label\": \"Cluster\"},\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=8, opacity=0.7))\n",
    "fig.update_layout(\n",
    "    width=900,\n",
    "    height=700,\n",
    "    legend=dict(title=\"Cluster\", orientation=\"v\"),\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
